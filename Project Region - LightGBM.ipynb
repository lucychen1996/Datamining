{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection, naive_bayes, svm, metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reports_with_vectors_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112095 entries, 0 to 112094\n",
      "Columns: 1009 entries, Unnamed: 0 to you\n",
      "dtypes: float64(1005), int64(1), object(3)\n",
      "memory usage: 862.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "southeast             23140\n",
       "pacific               21094\n",
       "midwest               19920\n",
       "northeast             16152\n",
       "southwest             10848\n",
       "other                  8660\n",
       "rockies                6533\n",
       "ontario                2027\n",
       "noncontiguous          1024\n",
       "british_columbia       1005\n",
       "prarie_provinces        883\n",
       "atlantic_provinces      413\n",
       "quebec                  345\n",
       "north_canada             50\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['region'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoded shape feature\n",
    "cat_cols = ['shape']\n",
    "\n",
    "for col in cat_cols:\n",
    "    temp = pd.get_dummies(df[col], prefix=col)\n",
    "    df= pd.concat([df, temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Encoder = LabelEncoder()\n",
    "y= Encoder.fit_transform(df['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(df['region'], y))\n",
    "d = pd.DataFrame(\n",
    "sorted(d.items(), key=lambda x: x[1], reverse=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atlantic_provinces</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>british_columbia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>midwest</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>noncontiguous</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>north_canada</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>northeast</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ontario</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>other</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pacific</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prarie_provinces</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>quebec</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rockies</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>southeast</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>southwest</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0   1\n",
       "0   atlantic_provinces   0\n",
       "1     british_columbia   1\n",
       "2              midwest   2\n",
       "3        noncontiguous   3\n",
       "4         north_canada   4\n",
       "5            northeast   5\n",
       "6              ontario   6\n",
       "7                other   7\n",
       "8              pacific   8\n",
       "9     prarie_provinces   9\n",
       "10              quebec  10\n",
       "11             rockies  11\n",
       "12           southeast  12\n",
       "13           southwest  13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns =['shape', 'Unnamed: 0','citystate','region','city_longitude','city_latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state=1, stratify=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_mdl_rand = lgb.LGBMClassifier(boosting_type = 'gbdt',\n",
    "                                n_jobs = -1,\n",
    "                                objective = 'multiclass',\n",
    "                                num_iterations = 3,\n",
    "                                metric = 'multi_logloss',\n",
    "                                pos_bagging_fraction = 0.5,\n",
    "                                  \n",
    "                               )\n",
    "\n",
    "lgb_grid_params_rand = { \n",
    "    'learning_rate': [0.5, 1, 3, 5],\n",
    "    'estimator__max_depth' : [10, 20, 30],\n",
    "    'num_leaves': [5, 10,15,20],\n",
    "    \n",
    "}\n",
    "\n",
    "lgb_gs_rand = RandomizedSearchCV(lgb_mdl_rand, lgb_grid_params_rand,\n",
    "                                 n_jobs=1, cv=4,\n",
    "                                 random_state=2)\n",
    "\n",
    "fit_params={\"early_stopping_rounds\" : 10,\n",
    "           \"eval_set\" : [[x_val, y_val]]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucyc\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 2.36421\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.20192\n",
      "[3]\tvalid_0's multi_logloss: 2.59947\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.20192\n",
      "[1]\tvalid_0's multi_logloss: 2.38961\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.25034\n",
      "[3]\tvalid_0's multi_logloss: 2.717\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.25034\n",
      "[1]\tvalid_0's multi_logloss: 2.37314\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.28007\n",
      "[3]\tvalid_0's multi_logloss: 2.76593\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.28007\n",
      "[1]\tvalid_0's multi_logloss: 2.37394\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.23254\n",
      "[3]\tvalid_0's multi_logloss: 2.68277\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.23254\n",
      "[1]\tvalid_0's multi_logloss: 2.50358\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 4.39094\n",
      "[3]\tvalid_0's multi_logloss: 5.25857\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 2.50358\n",
      "[1]\tvalid_0's multi_logloss: 2.57603\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 4.1874\n",
      "[3]\tvalid_0's multi_logloss: 5.35822\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 2.57603\n",
      "[1]\tvalid_0's multi_logloss: 2.66669\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 3.98071\n",
      "[3]\tvalid_0's multi_logloss: 7.29224\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 2.66669\n",
      "[1]\tvalid_0's multi_logloss: 2.52844\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 4.45133\n",
      "[3]\tvalid_0's multi_logloss: 5.23148\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 2.52844\n",
      "[1]\tvalid_0's multi_logloss: 2.75538\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 3.36448\n",
      "[3]\tvalid_0's multi_logloss: 3.84885\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 2.75538\n",
      "[1]\tvalid_0's multi_logloss: 2.86478\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 3.22688\n",
      "[3]\tvalid_0's multi_logloss: 4.32786\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 2.86478\n",
      "[1]\tvalid_0's multi_logloss: 2.90289\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 3.54304\n",
      "[3]\tvalid_0's multi_logloss: 4.71192\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 2.90289\n",
      "[1]\tvalid_0's multi_logloss: 2.87121\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 3.62002\n",
      "[3]\tvalid_0's multi_logloss: 3.56417\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 2.87121\n",
      "[1]\tvalid_0's multi_logloss: 2.0419\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.9841\n",
      "[3]\tvalid_0's multi_logloss: 2.00562\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 1.9841\n",
      "[1]\tvalid_0's multi_logloss: 2.03769\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.01688\n",
      "[3]\tvalid_0's multi_logloss: 2.07008\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.01688\n",
      "[1]\tvalid_0's multi_logloss: 2.04541\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.01042\n",
      "[3]\tvalid_0's multi_logloss: 2.06635\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.01042\n",
      "[1]\tvalid_0's multi_logloss: 2.04154\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.03197\n",
      "[3]\tvalid_0's multi_logloss: 2.06469\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.03197\n",
      "[1]\tvalid_0's multi_logloss: 2.1446\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.04083\n",
      "[3]\tvalid_0's multi_logloss: 2.13982\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.04083\n",
      "[1]\tvalid_0's multi_logloss: 2.13707\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.08432\n",
      "[3]\tvalid_0's multi_logloss: 2.19665\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.08432\n",
      "[1]\tvalid_0's multi_logloss: 2.14237\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.0376\n",
      "[3]\tvalid_0's multi_logloss: 2.21771\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.0376\n",
      "[1]\tvalid_0's multi_logloss: 2.13626\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.11217\n",
      "[3]\tvalid_0's multi_logloss: 2.18947\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.11217\n",
      "[1]\tvalid_0's multi_logloss: 3.03998\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 3.54724\n",
      "[3]\tvalid_0's multi_logloss: 4.11197\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 3.03998\n",
      "[1]\tvalid_0's multi_logloss: 3.25157\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 3.71524\n",
      "[3]\tvalid_0's multi_logloss: 4.52159\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 3.25157\n",
      "[1]\tvalid_0's multi_logloss: 3.1637\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 3.66435\n",
      "[3]\tvalid_0's multi_logloss: 4.39988\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 3.1637\n",
      "[1]\tvalid_0's multi_logloss: 3.10547\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 3.9071\n",
      "[3]\tvalid_0's multi_logloss: 3.78551\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 3.10547\n",
      "[1]\tvalid_0's multi_logloss: 3.17819\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 5.13633\n",
      "[3]\tvalid_0's multi_logloss: 12.2939\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 3.17819\n",
      "[1]\tvalid_0's multi_logloss: 3.32313\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 5.19261\n",
      "[3]\tvalid_0's multi_logloss: 5.82244\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 3.32313\n",
      "[1]\tvalid_0's multi_logloss: 3.3709\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 6.15082\n",
      "[3]\tvalid_0's multi_logloss: 6.24948\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 3.3709\n",
      "[1]\tvalid_0's multi_logloss: 3.29832\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 5.32811\n",
      "[3]\tvalid_0's multi_logloss: 6.54787\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 3.29832\n",
      "[1]\tvalid_0's multi_logloss: 2.83387\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 4.82\n",
      "[3]\tvalid_0's multi_logloss: 8.89178\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 2.83387\n",
      "[1]\tvalid_0's multi_logloss: 2.90091\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 4.74934\n",
      "[3]\tvalid_0's multi_logloss: 33.2217\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 2.90091\n",
      "[1]\tvalid_0's multi_logloss: 2.99768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 5.28496\n",
      "[3]\tvalid_0's multi_logloss: 5.89493\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 2.99768\n",
      "[1]\tvalid_0's multi_logloss: 2.93295\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 5.19707\n",
      "[3]\tvalid_0's multi_logloss: 10.4897\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 2.93295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 3.17819\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 5.13633\n",
      "[3]\tvalid_0's multi_logloss: 12.2939\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 3.17819\n",
      "[1]\tvalid_0's multi_logloss: 3.32313\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 5.19261\n",
      "[3]\tvalid_0's multi_logloss: 5.82244\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 3.32313\n",
      "[1]\tvalid_0's multi_logloss: 3.3709\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 6.15082\n",
      "[3]\tvalid_0's multi_logloss: 6.24948\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 3.3709\n",
      "[1]\tvalid_0's multi_logloss: 3.29832\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 5.32811\n",
      "[3]\tvalid_0's multi_logloss: 6.54787\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 3.29832\n",
      "[1]\tvalid_0's multi_logloss: 2.0419\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.9841\n",
      "[3]\tvalid_0's multi_logloss: 2.00562\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 1.9841\n",
      "[1]\tvalid_0's multi_logloss: 2.03769\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.01688\n",
      "[3]\tvalid_0's multi_logloss: 2.07008\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.01688\n",
      "[1]\tvalid_0's multi_logloss: 2.04541\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.01042\n",
      "[3]\tvalid_0's multi_logloss: 2.06635\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.01042\n",
      "[1]\tvalid_0's multi_logloss: 2.04154\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.03197\n",
      "[3]\tvalid_0's multi_logloss: 2.06469\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 2.03197\n",
      "[1]\tvalid_0's multi_logloss: 2.27036\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.27272\n",
      "[3]\tvalid_0's multi_logloss: 2.41766\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 2.27036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score='raise-deprecating',\n",
       "                   estimator=LGBMClassifier(boosting_type='gbdt',\n",
       "                                            class_weight=None,\n",
       "                                            colsample_bytree=1.0,\n",
       "                                            importance_type='split',\n",
       "                                            learning_rate=0.1, max_depth=-1,\n",
       "                                            metric='multi_logloss',\n",
       "                                            min_child_samples=20,\n",
       "                                            min_child_weight=0.001,\n",
       "                                            min_split_gain=0.0,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_iterations=3, num_leaves=31,\n",
       "                                            objective=...\n",
       "                                            random_state=None, reg_alpha=0.0,\n",
       "                                            reg_lambda=0.0, silent=True,\n",
       "                                            subsample=1.0,\n",
       "                                            subsample_for_bin=200000,\n",
       "                                            subsample_freq=0),\n",
       "                   iid='warn', n_iter=10, n_jobs=1,\n",
       "                   param_distributions={'estimator__max_depth': [10, 20, 30],\n",
       "                                        'learning_rate': [0.5, 1, 3, 5],\n",
       "                                        'num_leaves': [5, 10, 15, 20]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=2, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_gs_rand.fit(x_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train_predictions =lgb_gs_rand.predict(x_train)\n",
    "lgb_test_predictions= lgb_gs_rand.predict(x_test)\n",
    "\n",
    "train_probs_lgb_r = lgb_gs_rand.predict_proba(x_train)\n",
    "test_probs_lgb_r = lgb_gs_rand.predict_proba(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29528854195706716"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(lgb_train_predictions, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2825282126767474"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(lgb_test_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.188777229010912"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_train, train_probs_lgb_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2882975532677867"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, test_probs_lgb_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>1004</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>113</td>\n",
       "      <td>39</td>\n",
       "      <td>102</td>\n",
       "      <td>317</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>2279</td>\n",
       "      <td>17</td>\n",
       "      <td>3984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>509</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>265</td>\n",
       "      <td>23</td>\n",
       "      <td>117</td>\n",
       "      <td>215</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>1996</td>\n",
       "      <td>10</td>\n",
       "      <td>3230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>215</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>212</td>\n",
       "      <td>205</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>927</td>\n",
       "      <td>9</td>\n",
       "      <td>1732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>557</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>59</td>\n",
       "      <td>17</td>\n",
       "      <td>124</td>\n",
       "      <td>1345</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "      <td>1935</td>\n",
       "      <td>20</td>\n",
       "      <td>4219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>179</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>742</td>\n",
       "      <td>18</td>\n",
       "      <td>1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>659</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>133</td>\n",
       "      <td>321</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>3215</td>\n",
       "      <td>23</td>\n",
       "      <td>4628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>279</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>86</td>\n",
       "      <td>312</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>1139</td>\n",
       "      <td>206</td>\n",
       "      <td>2170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>133</td>\n",
       "      <td>122</td>\n",
       "      <td>3661</td>\n",
       "      <td>111</td>\n",
       "      <td>126</td>\n",
       "      <td>742</td>\n",
       "      <td>147</td>\n",
       "      <td>879</td>\n",
       "      <td>3007</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>150</td>\n",
       "      <td>12827</td>\n",
       "      <td>306</td>\n",
       "      <td>22419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1     2    3    4    5    6    7     8   9   10   11     12  \\\n",
       "True                                                                            \n",
       "0            2    1    14    0    1    4    1    5     7   1    1    0     45   \n",
       "1            1   31    24    3    4    6    4   11    23   7    0    4     82   \n",
       "2           28   14  1004    4   22  113   39  102   317  16   24    5   2279   \n",
       "3            2    1    20    4    0    5    0    5    20   1    2    3    141   \n",
       "4            0    0     4    0    0    0    0    0     2   0    0    0      4   \n",
       "5           22    7   509   12   12  265   23  117   215   8   21   13   1996   \n",
       "6            3    3   110    1    0    8   13   21    36   4    0    0    206   \n",
       "7           14   16   215   14   14   64   13  212   205   7   19    3    927   \n",
       "8           19   16   557   31   28   59   17  124  1345  10   20   38   1935   \n",
       "9            0    2    46    0    2    5    5   13    12   1    0    0     90   \n",
       "10           0    3    14    1    0    4    1    4    13   0    2    1     26   \n",
       "11           6    6   206    2    9   35   12   46   179   2   10   34    742   \n",
       "12          27   14   659   31   25  120   10  133   321  13   20   17   3215   \n",
       "13           9    8   279    8    9   54    9   86   312  10    9   32   1139   \n",
       "All        133  122  3661  111  126  742  147  879  3007  80  128  150  12827   \n",
       "\n",
       "Predicted   13    All  \n",
       "True                   \n",
       "0            0     82  \n",
       "1            1    201  \n",
       "2           17   3984  \n",
       "3            1    205  \n",
       "4            0     10  \n",
       "5           10   3230  \n",
       "6            0    405  \n",
       "7            9   1732  \n",
       "8           20   4219  \n",
       "9            1    177  \n",
       "10           0     69  \n",
       "11          18   1307  \n",
       "12          23   4628  \n",
       "13         206   2170  \n",
       "All        306  22419  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, lgb_test_predictions,\n",
    "            rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 20, 'learning_rate': 1, 'estimator__max_depth': 20}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_gs_rand.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(boosting_type = 'gbdt',\n",
    "                                n_jobs = -1,\n",
    "                                objective = 'multiclass',\n",
    "                                num_iterations = 3,\n",
    "                                metric = 'multi_logloss',\n",
    "                                pos_bagging_fraction = 0.5,\n",
    "                    num_leaves= 20, learning_rate= 1, estimator__max_depth=20)\n",
    "\n",
    "lgb_clf.fit(x_train,y_train)\n",
    "                \n",
    "region_shap_explainer = shap.TreeExplainer(lgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_shap_vals_train = region_shap_explainer.shap_values(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_shap_vals_test = region_shap_explainer.shap_values(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-26a6f5e70359>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# We can also plot the variable importance of all of our variables in a summary plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregion_shap_vals_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\shap\\plots\\summary.py\u001b[0m in \u001b[0;36msummary_plot\u001b[1;34m(shap_values, features, feature_names, max_display, plot_type, color, axis_color, title, alpha, show, sort, color_bar, plot_size, layered_violin_max_num_bins, class_names, color_bar_label, auto_size_plot)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;31m# order features by the sum of their effect magnitudes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[0mfeature_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[0mfeature_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We can also plot the variable importance of all of our variables in a summary plot\n",
    "shap.summary_plot(region_shap_vals_train, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
